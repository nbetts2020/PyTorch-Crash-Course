{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Crash Course\n",
        "\n",
        "Welcome to this PyTorch Crash Course! In this course, we'll cover everything from the basics of PyTorch (tensor and tensor manipulation) to more intermediate concepts such as building neural networks, culminating in a final project that fine-tunes a transformer based architecture (GPT2-Medium) for lyric completion. Let's get into it!"
      ],
      "metadata": {
        "id": "WOzssjGHEw23"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqoIxrmvqi5k"
      },
      "source": [
        "# PyTorch\n",
        "\n",
        "PyTorch is an open-source deep learning framework developed by Meta's AI Research lab. It's popular for its dynamic computation graph, which allows for flexible and interactive model design. This dynamic computation graph is different from other deep learning frameworks such as TensorFlow or Jax in that computations are not defined beforehand, often dubbed 'eager execution'. While slightly slower than static computation graphs, PyTorch's dynamic computation graphs allow for easy scalability to different dimensional inputs and clear debugging - a *must* amongst deep learning researchers. For this reason, and many others, PyTorch is widely used in academia, research, and industry for building deep learning models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEhpzGARrAvt"
      },
      "source": [
        "# Installation and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3p3Jh1EpzDa"
      },
      "outputs": [],
      "source": [
        "# Run this cell to install all dependencies needed for this crash course\n",
        "# Imports for certain packages are repeated periodically to ensure you can jump-\n",
        "# from section to section without having to run all previous code\n",
        "!wget https://raw.githubusercontent.com/nbetts2020/PyTorch-Crash-Course/main/requirements.txt\n",
        "!apt-get install -y python3-dev libcairo2-dev # needed to fix PyCairo import issue\n",
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are using Google Colab, click Runtime > Change Runtime Type > T4 GPU (or A100/V100 GPU if you have Colab Pro) > Save for the most optimal runtime"
      ],
      "metadata": {
        "id": "c9X3hfHJfe3j"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1YqmkP1rRKx"
      },
      "source": [
        "## Basics of PyTorch: Tensors\n",
        "\n",
        "Tensors are the primary data structures in PyTorch. They're akin to multi-dimensional arrays, and they form the backbone of many operations in deep learning. These tensors can be used to represent data in various dimensions:\n",
        "\n",
        "- A 0-dimensional tensor is a **scalar** (a single number): $a \\in \\mathbb{R}$\n",
        "- A 1-dimensional tensor is a **vector** (like an array of numbers): $\n",
        "   \\mathbf{v} = \\begin{pmatrix}\n",
        "   v_1 \\\\\n",
        "   v_2 \\\\\n",
        "   \\vdots \\\\\n",
        "   v_n\n",
        "   \\end{pmatrix} \\in \\mathbb{R}^n\n",
        "   $\n",
        "- A 2-dimensional tensor is a **matrix**: $\n",
        "   \\mathbf{M} = \\begin{pmatrix}\n",
        "   M_{11} & M_{12} & \\cdots & M_{1n} \\\\\n",
        "   M_{21} & M_{22} & \\cdots & M_{2n} \\\\\n",
        "   \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "   M_{m1} & M_{m2} & \\cdots & M_{mn}\n",
        "   \\end{pmatrix} \\in \\mathbb{R}^{m \\times n}\n",
        "   $\n",
        "- Tensors with three or more dimensions don't have special mathematical names but can be thought of as matrices with higher dimensions.\n",
        "\n",
        "In PyTorch, tensors can be created and manipulated using a variety of functions. They can also be operated on CPUs and GPUs (not to mention TPUs!), making computations faster and more efficient, especially for large-scale data.\n",
        "\n",
        "A crucial advantage of PyTorch tensors over NumPy arrays is their ability to run on GPUs. This accelerates computations considerably, making PyTorch particularly suitable for modern deep learning tasks.\n",
        "\n",
        "  Let's create some:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8LK7KQaHtgbn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bd22152-5cef-405c-cc2f-256f491ddca2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scalar: tensor(4.)\n",
            "\n",
            "Vector: tensor([1, 2, 3, 4])\n",
            "\n",
            "Matrix: tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "\n",
            "3D Tensor: tensor([[[1, 2],\n",
            "         [3, 4]],\n",
            "\n",
            "        [[5, 6],\n",
            "         [7, 8]]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Creating a scalar\n",
        "scalar = torch.tensor(4.0)\n",
        "print(\"Scalar:\", scalar)\n",
        "\n",
        "# Creating a vector\n",
        "vector = torch.tensor([1, 2, 3, 4])\n",
        "print(\"\\nVector:\", vector)\n",
        "\n",
        "# Creating a matrix\n",
        "matrix = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
        "print(\"\\nMatrix:\", matrix)\n",
        "\n",
        "# Creating a 3D tensor\n",
        "tensor3d = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
        "print(\"\\n3D Tensor:\", tensor3d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XBV4S3tuyS_"
      },
      "source": [
        "### Tensor Attributes\n",
        "\n",
        "Tensors have attributes that allow us to retrieve information about them:\n",
        "- `dtype`: The data type of the tensor (e.g., `float32`, `int64`).\n",
        "- `shape`: The dimensions of the tensor.\n",
        "- `device`: The device on which the tensor is stored, either `cpu` or `gpu`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cGD6b7NEuqKw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c81c48e4-73e4-41f9-b8a0-851f0f68cb79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix Data Type: torch.int64\n",
            "Matrix Shape: torch.Size([3, 2])\n",
            "Matrix Device: cpu\n"
          ]
        }
      ],
      "source": [
        "print(\"Matrix Data Type:\", matrix.dtype)\n",
        "print(\"Matrix Shape:\", matrix.shape)\n",
        "print(\"Matrix Device:\", matrix.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QXwqd42u-LC"
      },
      "source": [
        "### Tensor Operations\n",
        "\n",
        "Tensors support a number of operations, from basic addition to advanced linear algebra. Let's explore some of these operations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kCOb12cpuwhL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ee6b1a5-63dc-4855-b86a-c0c64c8e71ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Element-wise Addition: tensor([5, 7, 9])\n",
            "\n",
            "Element-wise Multiplication: tensor([ 4, 10, 18])\n",
            "\n",
            "Dot Product: tensor(32)\n",
            "\n",
            "Matrix Multiplication:\n",
            " tensor([[2, 4],\n",
            "        [6, 8]])\n"
          ]
        }
      ],
      "source": [
        "# Defining our two tensors, a and b\n",
        "a = torch.tensor([1, 2, 3])\n",
        "b = torch.tensor([4, 5, 6])\n",
        "\n",
        "# Element-wise addition\n",
        "sum_ab = a + b\n",
        "print(\"Element-wise Addition:\", sum_ab)\n",
        "\n",
        "# Element-wise multiplication\n",
        "product_ab = a * b\n",
        "print(\"\\nElement-wise Multiplication:\", product_ab)\n",
        "\n",
        "# Dot product\n",
        "dot_product = torch.dot(a, b)\n",
        "print(\"\\nDot Product:\", dot_product)\n",
        "\n",
        "# Matrix multiplication\n",
        "mat1 = torch.tensor([[1, 2], [3, 4]])\n",
        "mat2 = torch.tensor([[2, 0], [0, 2]])\n",
        "mat_product = torch.mm(mat1, mat2)\n",
        "print(\"\\nMatrix Multiplication:\\n\", mat_product)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: There's a few different ways of doing these operations. For example:"
      ],
      "metadata": {
        "id": "n4Cs0mS9kJO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example tensor\n",
        "tensor = torch.tensor([[1, 2], [3, 4]])\n",
        "\n",
        "# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n",
        "y1 = tensor @ tensor.T\n",
        "y2 = tensor.matmul(tensor.T)\n",
        "y3 = torch.matmul(tensor, tensor.T)\n",
        "print(\"\\nMatrix Multiplication (three methods):\\n\", y1, \"\\n\", y2, \"\\n\", y3)\n",
        "\n",
        "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
        "z1 = tensor * tensor\n",
        "z2 = tensor.mul(tensor)\n",
        "z3 = torch.mul(tensor, tensor)\n",
        "print(\"\\nElement-wise Multiplication (three methods):\\n\", z1, \"\\n\", z2, \"\\n\", z3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8Sma4zokIkt",
        "outputId": "b856fabd-4d8d-4dba-d475-27fda3e443ed"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Matrix Multiplication (three methods):\n",
            " tensor([[ 5, 11],\n",
            "        [11, 25]]) \n",
            " tensor([[ 5, 11],\n",
            "        [11, 25]]) \n",
            " tensor([[ 5, 11],\n",
            "        [11, 25]])\n",
            "\n",
            "Element-wise Multiplication (three methods):\n",
            " tensor([[ 1,  4],\n",
            "        [ 9, 16]]) \n",
            " tensor([[ 1,  4],\n",
            "        [ 9, 16]]) \n",
            " tensor([[ 1,  4],\n",
            "        [ 9, 16]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2EWPHElvjGY"
      },
      "source": [
        "### Reshaping Tensors\n",
        "\n",
        "In deep learning, it's common to reshape tensors. For example, when passing data through neural networks, the expected input shape of one layer might be different from the output shape of the previous layer.\n",
        "\n",
        "Let's go through a detailed example of this in Convolution Neural Networks (CNNs; more on them later!):\n",
        "\n",
        "**Input Layer**: The network starts with the input image in the shape (28, 28, 1) for a grayscale image. Each pixel's brightness is represented by a value in this 3D tensor.\n",
        "\n",
        "**Convolutional Layer**: After the input layer, a convolutional layer might process this image. This layer applies several filters to detect different features in the image, such as edges or textures. The output of this convolutional layer will typically have more channels. For example, the output could be in the shape (26, 26, 32), where 32 is the number of filters used.\n",
        "\n",
        "**Flattening Layer**: Before connecting to a fully connected (dense) layer (a type of hidden layer within the network), the output from the convolutional layers is often flattened. This means converting the 3D tensor into a 2D tensor. For example, if the output shape from the convolutional layers is (26, 26, 32), it gets reshaped to (batch_size, 26 * 26 * 32). If the batch size is 64, it becomes (64, 21632).\n",
        "\n",
        "**Fully Connected Layer**: This reshaped tensor is then passed to a fully connected layer, which processes it to produce the final output, such as class scores for classification tasks.\n",
        "\n",
        "By doing this, you ensure that the data format is compatible with the input requirements of the next layer in the neural network.\n",
        "\n",
        "`view()` and `reshape()` are two methods to achieve this. While they generally serve the same purpose, there are nuances in their behavior, especially concerning memory layout. However, for most purposes, they can be used interchangeably. For more information: https://saturncloud.io/blog/whats-the-difference-between-reshape-and-view-in-pytorch/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cgZjoGZnvOZT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "163e194c-8bdd-4a7d-b7f0-dfe040199788"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matrix:\n",
            " tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6]])\n",
            "\n",
            "matrix reshaped using view(2,3) 3x2 -> 2x3:\n",
            " tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "\n",
            "vector:\n",
            " tensor([1, 2, 3, 4])\n",
            "\n",
            "vector reshaped using reshape(2,2) 1x4 -> 2x2:\n",
            " tensor([[1, 2],\n",
            "        [3, 4]])\n"
          ]
        }
      ],
      "source": [
        "# Using view()\n",
        "reshaped_matrix = matrix.view(2, 3)\n",
        "print(\"matrix:\\n\", matrix)\n",
        "print(\"\\nmatrix reshaped using view(2,3) 3x2 -> 2x3:\\n\", reshaped_matrix)\n",
        "\n",
        "# Using reshape()\n",
        "reshaped_vector = vector.reshape(2, 2)\n",
        "print(\"\\nvector:\\n\", vector)\n",
        "print(\"\\nvector reshaped using reshape(2,2) 1x4 -> 2x2:\\n\", reshaped_vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU_ZGcfyyXvX"
      },
      "source": [
        "### Broadcasting\n",
        "\n",
        "Broadcasting is a powerful mechanism that allows PyTorch to work with tensors of different shapes when performing arithmetic operations. With broadcasting, the smaller tensor is 'broadcast' over the larger tensor so they have compatible shapes.\n",
        "\n",
        "This is useful because it eliminates the need for manually reshaping tensors in many scenarios. For more information: https://pytorch.org/docs/stable/notes/broadcasting.html\n",
        "\n",
        "Let's try it out:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzWaef89yYIl"
      },
      "outputs": [],
      "source": [
        "# Broadcasting in action\n",
        "x = torch.tensor([1, 2, 3])\n",
        "y = 2  # Scalar\n",
        "\n",
        "# This will multiply every element of 'x' by 'y'\n",
        "result = x * y\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OHiyNcIz6_G"
      },
      "source": [
        "### Tensor Indexing\n",
        "\n",
        "Just like with Python lists and NumPy arrays, you can index and slice PyTorch tensors. This allows for selecting specific parts of a tensor, which is useful for data manipulation and preprocessing. For more information: https://deeplearninguniversity.com/pytorch/pytorch-tensor-indexing/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMzYefo9zCtB"
      },
      "outputs": [],
      "source": [
        "# Tensor Indexing\n",
        "tensor = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "\n",
        "# Get the second row\n",
        "second_row = tensor[1]\n",
        "print(\"Second Row:\", second_row)\n",
        "\n",
        "# Get the first column - [row:column] -> [:, 0] -> ':' = all rows,\n",
        "# '0' = 0th element of all rows (first column)\n",
        "first_column = tensor[:, 0]\n",
        "print(\"\\nFirst Column:\", first_column)\n",
        "\n",
        "# Get the last two elements of the last row\n",
        "sub_tensor = tensor[-1, -2:]\n",
        "print(\"\\nSub-tensor:\", sub_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALb4Ta2q1hYU"
      },
      "source": [
        "### In-place Operations\n",
        "\n",
        "PyTorch supports in-place operations, which modify tensors directly without creating a new one. Such operations are suffixed with an underscore (`_`). While they save memory by not creating new tensors, caution is needed, especially when computing gradients, as in-place modifications can sometimes hinder the process of computing gradients. For more information on in-place operations and its downsides: https://towardsdatascience.com/in-place-operations-in-pytorch-f91d493e970e\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sp1K11f-3yvD"
      },
      "source": [
        "### Tensor to Numpy and Back\n",
        "\n",
        "If you are unfamiliar with NumPy, NumPy is a library in Python that supports the use of \"large, multi-dimensional arrays and matrices, as well as accompanying high-level mathematical functions to opperate on these arrays\". PyTorch provides easy conversions between PyTorch tensors and NumPy arrays. This interoperability is particularly useful for data manipulation and preprocessing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RLWDiS401X7"
      },
      "outputs": [],
      "source": [
        "# Convert tensor to numpy array\n",
        "numpy_arr = tensor.numpy()\n",
        "print(\"Numpy Array:\\n\", numpy_arr)\n",
        "\n",
        "# Convert numpy array back to tensor\n",
        "new_tensor = torch.from_numpy(numpy_arr)\n",
        "print(\"\\nTensor:\\n\", new_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4algfz2d43BN"
      },
      "source": [
        "### Using GPUs\n",
        "\n",
        "One of the strengths of PyTorch is its ability to perform computations on GPUs. This is especially useful for deep learning tasks, as GPUs can significantly accelerate these computations. Moving tensors between the CPU and GPU is a line of code away!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxxKonWe4sif"
      },
      "outputs": [],
      "source": [
        "# Check if CUDA (GPU interface) is available\n",
        "if torch.cuda.is_available():\n",
        "    # Move tensor to GPU\n",
        "    tensor_gpu = tensor.cuda()\n",
        "    print(\"Tensor on GPU: \", tensor_gpu.device)\n",
        "else:\n",
        "    print(\"CUDA not available. Cannot move tensor to GPU.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zVIRWdxWWik"
      },
      "source": [
        "## Building Basic Neural Networks with PyTorch\n",
        "\n",
        "Now that we've explored tensors, let's explore one of the most exciting aspects of working with PyTorch: building neural networks! PyTorch provides the `nn` module, a comprehensive suite of tools to create and train neural networks. Let's start by understanding the basic components:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcda5wL1W5MK"
      },
      "source": [
        "### Layers\n",
        "\n",
        "Neural networks are composed of layers. Each layer contains neurons that process some input and produce an output. PyTorch's `nn` module provides pre-defined layers that can be easily plugged into models. We'll discuss a few common ones:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4bqktwiYhz5"
      },
      "source": [
        "#### Linear (Fully Connected) Layers\n",
        "\n",
        "The Linear layer, often termed as \"fully connected layer\", connects every neuron from the previous layer to every neuron in the current layer. It is the most fundamental layer in neural networks and is utilized in a wide variety of architectures, from simple feed-forward networks to more complex models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZYOst7XWwhm"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# A linear layer with 5 input features and 3 output features\n",
        "linear_layer = nn.Linear(in_features=5, out_features=3)\n",
        "print(linear_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2m9liTsY1vH"
      },
      "source": [
        "#### Convolutional Layers\n",
        "\n",
        "Convolutional layers are the cornerstone of Convolutional Neural Networks (CNNs). They are specially designed to recognize patterns in images, such as edges, corners, textures, etc. Unlike fully connected layers, they look for patterns in local regions of the input, making them more efficient for image data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfviECsDYpg2"
      },
      "outputs": [],
      "source": [
        "# A 2D convolutional layer with 1 input channel, 3 output channels, and a kernel size of 3\n",
        "conv_layer = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=3)\n",
        "print(conv_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdrcmLpMY9xZ"
      },
      "source": [
        "#### Pooling Layers\n",
        "\n",
        "Pooling layers are often used after convolutional layers in CNNs. They reduce the spatial dimensions (width, height) of the input, making the network less computationally intensive and more invariant to small translations in the image. The most common type of pooling is MaxPooling, which takes the maximum value in a local region of the input.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EM01rurfY5kH"
      },
      "outputs": [],
      "source": [
        "# A 2D max pooling layer with a kernel size of 2 and stride of 2\n",
        "pooling_layer = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "print(pooling_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-y9kUSOmY8QR"
      },
      "source": [
        "#### Linear Layer Example\n",
        "\n",
        "Now that we've introduced a few different types of layers, let's delve into a more in-depth example using the Linear layer. We'll demonstrate how data passes through this layer and how it transforms the input. Remember, a Linear layer essentially learns a linear transformation of the data. It multiplies the input with learned weights and adds a bias term.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4ypRAWnZnCa"
      },
      "outputs": [],
      "source": [
        "# Define a linear layer\n",
        "# Input features = 2 (for simplicity, consider this as 2D data points: x and y coordinates)\n",
        "# Output features = 1 (a transformed single value for each 2D data point)\n",
        "linear = nn.Linear(2, 1)\n",
        "\n",
        "# Let's print out the initial weights and bias - set initially to random values\n",
        "print(\"Initial weights:\", linear.weight)\n",
        "print(\"Initial bias:\", linear.bias)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ETJ4ZbQaolf"
      },
      "source": [
        "The Linear layer has initialized weights and biases. These values will be learned and adjusted during the training process to minimize the loss. For now, let's see how our layer transforms a sample input using these initial values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuQTcA7raJsS"
      },
      "outputs": [],
      "source": [
        "# Sample input: Two 2D points\n",
        "input_data = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
        "\n",
        "# Pass the data through the linear layer\n",
        "output_data = linear(input_data)\n",
        "\n",
        "print(\"Transformed Data:\", output_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKjN7QcPbNBj"
      },
      "source": [
        "As you can see, our 2D data points are transformed into 1D values. The transformation is a result of the matrix multiplication between the input data and the layer's weights, followed by the addition of the bias term.\n",
        "\n",
        "This example provides a basic understanding of how data flows through a Linear layer. When building neural networks, these layers are stacked together, often with activation functions in between, to learn more complex and nuanced transformations from the input to the output. For more information: https://ecoagi.ai/topics/Python/nn-linear"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYkY-xJh7s6S"
      },
      "source": [
        "### Activation Functions\n",
        "\n",
        "After processing input through a layer, it's common to pass the output through an activation function. These functions introduce non-linearity into the model, enabling it to learn complex patterns. Popular activation functions include ReLU, Sigmoid, and Tanh. Let's focus on ReLU. Here's the ReLU activation function:\n",
        "\n",
        "- $ \\text{ReLU}(x) = \\max(0, x)$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tENhZzVPbEkg"
      },
      "outputs": [],
      "source": [
        "# Define a ReLU activation function\n",
        "relu = nn.ReLU()\n",
        "\n",
        "# Sample tensor\n",
        "x = torch.tensor([-2.0, -1.0, 0.0, 1.0, 2.0])\n",
        "\n",
        "# Pass tensor through ReLU - passing through every element (say x) in tensor: if\n",
        "# less than 0, return 0, else return x\n",
        "activated_x = relu(x)\n",
        "print(activated_x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkJfZKnPGFUp"
      },
      "source": [
        "### Building a Simple Feed-forward Neural Network\n",
        "\n",
        "With knowledge of layers and activation functions, we can now assemble them into a neural network. Here, we'll construct a basic feed-forward neural network, also known as a multi-layer perceptron (MLP). An MLP is a type of neural network where information flows in one direction: from the input layer, through hidden layers, to the output layer. There are no loops or cycles in the network. For more information about MLPs: https://towardsdatascience.com/multilayer-perceptron-explained-with-a-real-life-example-and-python-code-sentiment-analysis-cb408ee93141 (code written in sklearn, but same idea conceptually). Let's build a simple MLP with one hidden layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNstfGV-7yNl"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(2, 3)  # Input layer with 2 features, outputs 3 values\n",
        "        self.fc2 = nn.Linear(3, 1)  # Hidden layer with 3 input values, outputs 1 value\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.ReLU()(self.fc1(x))\n",
        "        return self.fc2(x)\n",
        "\n",
        "# Instantiating the network\n",
        "mlp = MLP()\n",
        "print(mlp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ip-3oak6ZH_2"
      },
      "source": [
        "Now that our network is defined, we need a loss function to measure how well our network is performing. Since our task is a regression (predicting a continuous value), we'll use Mean Squared Error (MSE) as our loss function. Additionally, we'll define an optimizer to adjust the weights of our network based on this loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmxvcmXHGRz8"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "# Defining a mean squared error loss\n",
        "mse_loss = nn.MSELoss()\n",
        "\n",
        "# Defining an SGD optimizer\n",
        "optimizer = optim.SGD(mlp.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAWeVUyUZkdF"
      },
      "source": [
        "With our network, loss function, and optimizer in place, let's create some example data to demonstrate how this MLP works. We are creating a simple example of how neural networks can approximate functions (in this case a very trivial example of summing two numbers together!)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXTwDwjwZNFU"
      },
      "outputs": [],
      "source": [
        "# Generate some synthetic data\n",
        "# Input: 10 samples with 2 features each\n",
        "inputs = torch.rand(10, 2)\n",
        "\n",
        "# Target: A simple function of the inputs (sum of the two features)\n",
        "# This will be our ground truth for training\n",
        "targets = inputs.sum(dim=1, keepdim=True)\n",
        "\n",
        "print(\"Inputs:\\n\", inputs)\n",
        "print(\"\\nTargets:\\n\", targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pJ8EMzGZ_6f"
      },
      "source": [
        "Now, let's train our MLP on this data for a few epochs. An epoch is one complete forward and backward pass of all training samples. Remember:\n",
        "\n",
        "- A **forward pass** is when you input your data into the model to get the predictions. This involves passing the input data through each layer of the neural network and applying the associated weights and biases to produce the final output (predictions).\n",
        "\n",
        "- A **backward pass** (often referred to as backpropagation) is the process by which the neural network adjusts its weights and biases in response to the error in its predictions. This involves calculating the gradient of the loss function with respect to the model's weights and biases and updating them in a direction that reduces the error. The magnitude of this update is determined by the learning rate.\n",
        "\n",
        "During each epoch, the model will make predictions (forward pass), calculate the loss (difference between predictions and actual values), and then update its weights and biases to reduce the loss (backward pass)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8rdmAsuZp4C"
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass\n",
        "    outputs = mlp(inputs)\n",
        "    loss = mse_loss(outputs, targets)\n",
        "\n",
        "    # Backward pass and optimization\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print loss every 20 epochs\n",
        "    if (epoch+1) % 20 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaTyeLUJaILe"
      },
      "source": [
        "After training, our network has adjusted its weights to minimize the loss. You can now pass new data through this trained MLP to make predictions. This hands-on example provides a glimpse into the process of defining, training, and using a neural network in PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIdqxNYLf2Ds"
      },
      "source": [
        "### Testing the Trained MLP\n",
        "\n",
        "After training our model, it's crucial to test its performance on new, unseen data. This allows us to evaluate how well our model generalizes beyond the training data. Let's generate some test data and see how our MLP predicts the target values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvlEz8AyaDCp"
      },
      "outputs": [],
      "source": [
        "# Generate synthetic test data\n",
        "test_inputs = torch.rand(5, 2)\n",
        "test_targets = test_inputs.sum(dim=1, keepdim=True)\n",
        "\n",
        "# Predict using the trained model\n",
        "test_outputs = mlp(test_inputs)\n",
        "\n",
        "print(\"Test Inputs:\\n\", test_inputs)\n",
        "print(\"\\nTrue Test Targets:\\n\", test_targets)\n",
        "print(\"\\nPredicted Test Targets:\\n\", test_outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhwAh5lSgHRq"
      },
      "source": [
        "By comparing the true test targets with the predicted values, we can now get a precise sense of how close our model's predictions are to the actual values. Remember, the closer the predictions are to the true targets, the better our model is performing on the test data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZXF4vSyiJFG"
      },
      "source": [
        "### Datasets\n",
        "\n",
        "In PyTorch, a dataset is represented by a class that extends the `Dataset` class. This class requires two essential methods to be implemented:\n",
        "- `__len__()`: Returns the number of samples in the dataset.\n",
        "- `__getitem__()`: Allows indexing to fetch a specific data sample.\n",
        "\n",
        "Let's explore a simple custom dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_b3o38ziJ8k"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels[idx]\n",
        "\n",
        "# Example usage\n",
        "data_samples = torch.randn(10, 2)  # 10 samples with 2 features each\n",
        "labels = torch.randint(0, 2, (10,))  # Binary labels for each sample\n",
        "\n",
        "dataset = CustomDataset(data_samples, labels)\n",
        "\n",
        "# Fetch the fourth sample - (tensor with 2 features, binary classification tensor)\n",
        "print(dataset[3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xgs7hpJi17z"
      },
      "source": [
        "### DataLoaders\n",
        "\n",
        "While `Dataset` provides a representation of data, `DataLoader` wraps a dataset and provides utilities to create batches of data, shuffle the data, and load data in parallel. It's an essential tool for training models, as it feeds data in manageable chunks, allowing for efficient memory usage and faster training. For more information about `DataLoader` and the different types of datasets included in the PyTorch library: https://blog.paperspace.com/dataloaders-abstractions-pytorch/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIxijcFDiTlg"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Create a DataLoader\n",
        "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "# Iterate over the dataloader to fetch batches\n",
        "for batch_data, batch_labels in dataloader:\n",
        "    print(\"Batch data:\", batch_data)\n",
        "    print(\"Batch labels:\", batch_labels)\n",
        "    break  # Just printing the first batch for demonstration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h38XIUUIpZkf"
      },
      "source": [
        "## Building Advanced Neural Networks with PyTorch\n",
        "\n",
        "Now that we've explored some of the basics of building basic neural networks in PyTorch, let's journey into making more advanced neural networks!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Un1NmcTp7Re"
      },
      "source": [
        "### Convolutional Neural Networks (CNNs)\n",
        "\n",
        "Convolutional Neural Networks (CNNs) have revolutionized the field of computer vision. They're designed to automatically and adaptively learn spatial hierarchies of features from images. CNNs are characterized by their use of convolutional layers, which apply convolutional filters to the input data. For a more in-depth look at CNNs: https://colah.github.io/posts/2014-07-Conv-Nets-Modular/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGKq6gsKjCwO"
      },
      "outputs": [],
      "source": [
        "# A simple CNN architecture\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3)  # First convolutional layer\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)  # Pooling layer\n",
        "        self.fc1 = nn.Linear(16 * 13 * 13, 10)  # Fully connected layer (for a 28x28 input image)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(nn.ReLU()(self.conv1(x)))\n",
        "        x = x.view(-1, 16 * 13 * 13)\n",
        "        x = nn.ReLU()(self.fc1(x))\n",
        "        return x\n",
        "\n",
        "cnn = SimpleCNN()\n",
        "print(cnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2oY_sukD4uK"
      },
      "source": [
        "### Recurrent Neural Networks (RNNs)\n",
        "\n",
        "Recurrent Neural Networks (RNNs) are designed to recognize patterns in sequences of data, such as text, genomes, and time series data. They maintain a 'memory' of previous inputs in their internal state, allowing them to produce output influenced by the entire observed sequence. For more (a lot more) information, check out this blog post by Andrej Karpathy: http://karpathy.github.io/2015/05/21/rnn-effectiveness/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flFsmVigDmBK"
      },
      "outputs": [],
      "source": [
        "# A simple RNN architecture\n",
        "class SimpleRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(SimpleRNN, self).__init__()\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out, _ = self.rnn(x)\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "rnn = SimpleRNN(input_size=10, hidden_size=20, output_size=2)\n",
        "print(rnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wC1fAJ7gFGa6"
      },
      "source": [
        "### CNN Example: Cat vs. Dog Image Classification using CIFAR-10\n",
        "\n",
        "While CIFAR-10 contains 10 classes, for our binary classification task, we'll focus on just two: cats and dogs. Let's first load and preprocess the CIFAR-10 dataset, filtering out only the images of cats and dogs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IA1w2EAwD8Jn"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms, datasets\n",
        "\n",
        "# Defining transformations for the dataset\n",
        "# 1. Convert image data to a PyTorch tensor\n",
        "# 2. Normalize the image data to have values between -1 and 1\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# Downloading the CIFAR-10 dataset\n",
        "# - root: Specifies the directory where the dataset will be stored\n",
        "# - train: Specifies whether to download the training set or the test set\n",
        "# - download: If True, downloads the dataset from the internet\n",
        "# - transform: Specifies the transformations to be applied on the data\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Filter the dataset to retain only images of cats and dogs\n",
        "# In CIFAR-10, cats are labeled as 3 and dogs as 5\n",
        "\n",
        "# For the training dataset\n",
        "# Filter images\n",
        "train_dataset.data = train_dataset.data[(train_dataset.targets == 3) | (train_dataset.targets == 5)]\n",
        "# Adjust labels: Set dogs (label 5) as 1 and cats (label 3) as 0\n",
        "train_dataset.targets = [1 if label == 5 else 0 for label in train_dataset.targets if label == 3 or label == 5]\n",
        "\n",
        "# For the test dataset\n",
        "# Filter images\n",
        "test_dataset.data = test_dataset.data[(test_dataset.targets == 3) | (test_dataset.targets == 5)]\n",
        "# Adjust labels: Set dogs (label 5) as 1 and cats (label 3) as 0\n",
        "test_dataset.targets = [1 if label == 5 else 0 for label in test_dataset.targets if label == 3 or label == 5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kLfgHv1FWQT"
      },
      "source": [
        "With our data loaded and preprocessed, we can now define a simple CNN model suitable for the CIFAR-10 dataset's image dimensions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZ_M8BFBGZ4e"
      },
      "source": [
        "### Building the CNN Model\n",
        "\n",
        "For our binary classification task (Cat vs. Dog), we'll construct a simple CNN model. This model will have a couple of convolutional layers followed by pooling layers, and finally some fully connected layers for classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pjvg07jIFYiC"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CatDogCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CatDogCNN, self).__init__()\n",
        "        # First convolutional layer (3 input channels, 16 output channels, 3x3 kernel)\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        # Second convolutional layer (16 input channels, 32 output channels, 3x3 kernel)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        # Pooling layer to reduce spatial dimensions by half\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        # Fully connected layer (32 channels * 8 * 8 image size to 256 nodes)\n",
        "        self.fc1 = nn.Linear(32 * 8 * 8, 256)\n",
        "        # Final output layer (from 256 nodes to 2 nodes - Cat & Dog)\n",
        "        self.fc2 = nn.Linear(256, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 32 * 8 * 8)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the CNN model\n",
        "model = CatDogCNN()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qM3pOUA_GuIb"
      },
      "source": [
        "### Training the CNN Model\n",
        "\n",
        "With our model defined, it's time to train it on our Cat vs. Dog dataset. Training involves:\n",
        "1. Passing input data through the model (forward pass).\n",
        "2. Calculating the loss using the predictions and actual labels.\n",
        "3. Backpropagating the error and adjusting the model weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gMmmuNrGleq"
      },
      "outputs": [],
      "source": [
        "# Filter the dataset for only cats (class label 3) and dogs (class label 5) - doing it again here for the sake of example\n",
        "def filter_cats_dogs(data, targets):\n",
        "    filtered_data = [data[i] for i, label in enumerate(targets) if label in [3, 5]]\n",
        "    # Adjust labels: Set dogs (label 5) as 1 and cats (label 3) as 0\n",
        "    filtered_targets = [1 if label == 5 else 0 for label in targets if label in [3, 5]]\n",
        "    return filtered_data, filtered_targets\n",
        "\n",
        "# Redownload and initialize the CIFAR-10 dataset\n",
        "original_train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "original_test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Use the filter_cats_dogs function to filter the dataset\n",
        "train_dataset.data, train_dataset.targets = filter_cats_dogs(original_train_dataset.data, original_train_dataset.targets)\n",
        "test_dataset.data, test_dataset.targets = filter_cats_dogs(original_test_dataset.data, original_test_dataset.targets)\n",
        "\n",
        "# Check the lengths after filtering\n",
        "print(\"Length of filtered training dataset:\", len(train_dataset.data))\n",
        "print(\"Length of filtered test dataset:\", len(test_dataset.data))\n",
        "\n",
        "# Define DataLoader for the training dataset\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()  # Since it's a classification problem with 2 classes\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Using the Adam optimizer with a learning rate of 0.001\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        # Calculate loss\n",
        "        loss = criterion(outputs, labels)\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "print(\"Finished Training!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHjca33vIwHB"
      },
      "source": [
        "### Evaluating the CNN Model\n",
        "\n",
        "After training, it's essential to evaluate our model's performance on unseen data. We'll assess our model using the test dataset and compute the accuracy of the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUYacq44G7Jq"
      },
      "outputs": [],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_dataset:\n",
        "        outputs = model(images.unsqueeze(0))  # Add batch dimension\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += 1  # Since labels is an integer, just increment total by 1\n",
        "        correct += (predicted.item() == labels)\n",
        "\n",
        "print(f\"Accuracy on test data: {100 * (correct / total)}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiV4i-4oh2sp"
      },
      "source": [
        "Try it for yourself!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crTGsdVkeSzt"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "def predict_from_url(url, model):\n",
        "    # Fetch image from the internet\n",
        "    response = requests.get(url)\n",
        "    img = Image.open(BytesIO(response.content))\n",
        "\n",
        "    # Process the image\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((32, 32)),  # Assuming the model expects 32x32 images\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    img_tensor = transform(img).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "    # Get the model's prediction\n",
        "    with torch.no_grad():\n",
        "        output = model(img_tensor)\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        if predicted.item() == 1:\n",
        "            return \"Dog\"\n",
        "        else:\n",
        "            return \"Cat\"\n",
        "\n",
        "# Example usage:\n",
        "url = \"https://i.natgeofe.com/n/548467d8-c5f1-4551-9f58-6817a8d2c45e/NationalGeographic_2572187_square.jpg\"\n",
        "print(predict_from_url(url, model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcZMIHyCk097"
      },
      "source": [
        "## Regularization and Optimization Techniques\n",
        "\n",
        "As we build deeper and more complex neural networks, there's a risk of overfitting, where our model performs exceptionally well on the training data but poorly on unseen data. Regularization techniques help prevent overfitting, making the model more generalizable. Additionally, optimization techniques can aid in faster and more stable training.\n",
        "\n",
        "In this section, we will explore some of these techniques, including Dropout, Batch normalization, and Learning rate scheduling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5AnF2mplBi3"
      },
      "source": [
        "### Dropout\n",
        "\n",
        "Dropout is a regularization technique that can help prevent overfitting in neural networks. During training, dropout is implemented by only keeping a neuron active with some probability $ p$ (a hyperparameter), or setting it to zero otherwise. By \"dropping out\" a random set of activations in this way, we ensure that no single neuron can memorize the data, making the model more robust.\n",
        "\n",
        "The probability $ p$ is the fraction of the input units to drop. For example, if $ p$ is set to 0.5, then roughly half of the input units will be dropped out during training. For a visual understanding of it: https://www.youtube.com/watch?v=ARq74QuavAo\n",
        "\n",
        "Let's see how to implement dropout in PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab2lCz0UIy1u"
      },
      "outputs": [],
      "source": [
        "class DropoutNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(DropoutNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        # Dropout layer: during training, randomly sets approximately 50% of its input units to 0\n",
        "        # to prevent over-reliance on any individual neuron.\n",
        "        self.dropout = nn.Dropout(0.5)  # 0.5 is the probability of dropping an activation\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)  # apply dropout during training\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model with dropout\n",
        "dropout_model = DropoutNN(input_size=784, hidden_size=256, output_size=10)\n",
        "print(dropout_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eZDcMXqmu1b"
      },
      "source": [
        "### Batch Normalization\n",
        "\n",
        "Batch normalization is an optimization technique designed to stabilize and accelerate the training of deep neural networks. Here's how it works:\n",
        "\n",
        "1. **Normalization**: During training, for each mini-batch, batch normalization computes the mean and variance of the activations of a layer. It then normalizes the activations to have a mean of zero and a standard deviation of one.\n",
        "2. **Scaling and Shifting**: After normalization, batch normalization introduces two learnable parameters, scale and shift, for each activation. This allows the model to scale and shift the normalized activations if it determines that the original mean and variance were beneficial.\n",
        "\n",
        "The key benefits of batch normalization are:\n",
        "\n",
        "- **Smoothing the Optimization Landscape**: One of the primary benefits of batch normalization is that it smooths the optimization landscape, making the loss surface more tractable for gradient-based optimization methods. This can lead to faster training and less sensitivity to the initialization of weights.\n",
        "- **Faster Convergence**: By ensuring that activations have a consistent distribution, the training process becomes more stable, allowing for higher learning rates and faster convergence.\n",
        "- **Acts as a Regularizer**: Batch normalization can also serve as a form of regularization. The noise introduced during training, due to the use of mini-batch statistics, can improve generalization in some cases, reducing the need for other regularization techniques like dropout.\n",
        "- **Mitigating Internal Covariate Shift**\\*: Originally, it was believed that batch normalization primarily worked by reducing internal covariate shift, which refers to the change in the distribution of layer activations as the network trains. While normalization does address this, recent research suggests that this might not be the primary reason for the effectiveness of BatchNorm. Nonetheless, it's a point of consideration.\n",
        "\n",
        "For some resources providing a visual understanding of Batch Normalization: https://www.youtube.com/watch?v=DtEq44FTPM4, https://www.youtube.com/watch?v=nUUqwaxLnWs\n",
        "\n",
        "With this understanding, let's see how batch normalization is implemented in PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjpwavYWlFAZ"
      },
      "outputs": [],
      "source": [
        "class BatchNormNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(BatchNormNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        # Batch normalization layer for the hidden layer\n",
        "        self.batchnorm = nn.BatchNorm1d(hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.batchnorm(x)  # apply batch normalization\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model with batch normalization\n",
        "batchnorm_model = BatchNormNN(input_size=784, hidden_size=256, output_size=10)\n",
        "print(batchnorm_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYnX_8Cu6LAc"
      },
      "source": [
        "### Learning Rate Scheduling\n",
        "\n",
        "The learning rate is one of the most crucial hyperparameters to set in training deep neural networks. It determines the step size at each iteration while moving towards a minimum of the loss function. Set it too high, and the algorithm might overshoot the minimum; too low, and the training might become exceedingly slow.\n",
        "\n",
        "Learning Rate Scheduling provides a solution to adapt the learning rate during training. Instead of using a fixed learning rate, we adjust it over time. This allows us to start with a larger learning rate, which decreases as we get closer to the minimum, ensuring faster convergence and better final performance.\n",
        "\n",
        "There are various strategies for learning rate scheduling, such as Step Decay, Exponential Decay, and Cosine Annealing. In this section, we will explore Step Decay and implement it!\n",
        "\n",
        "For a visual understanding of the different types of learning rate decay: https://www.youtube.com/watch?v=QzulmoOg2JE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lX8zdzed6TiW"
      },
      "source": [
        "### StepLR - Step Decay Learning Rate\n",
        "\n",
        "Step Decay is a strategy where the learning rate is reduced by a factor every few epochs. For instance, if our initial learning rate is 0.1 and we have a decay factor (often called gamma) of 0.1, the learning rate will drop to 0.01 after a specified number of epochs, referred to as the `step_size`. This approach allows the model to make larger updates at the beginning of the training, capturing coarse-grained features, and then make smaller, fine-tuning updates later on to refine its understanding.\n",
        "\n",
        "In PyTorch, we can implement Step Decay with the `StepLR` scheduler. The step_size parameter determines the epoch interval at which the learning rate will be reduced.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYHxjCX41i_G"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "# Data loading and preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load only a subset of MNIST for faster demonstration\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "# Use only 1/10 of the dataset\n",
        "train_subset, _ = random_split(train_dataset, [len(train_dataset) // 10, len(train_dataset) - len(train_dataset) // 10])\n",
        "train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Define a simple model for demonstration\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc = nn.Linear(28*28, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        return self.fc(x)\n",
        "\n",
        "# Instantiate the model, criterion, and optimizer\n",
        "model = SimpleNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)  # initial learning rate set to 0.1\n",
        "\n",
        "# Define StepLR scheduler with a smaller step size\n",
        "scheduler = StepLR(optimizer, step_size=5)\n",
        "\n",
        "# Training loop with learning rate scheduling over fewer epochs\n",
        "num_epochs = 15\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Learning Rate: {scheduler.get_last_lr()[0]}\")\n",
        "    scheduler.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5BK6K8__d9x"
      },
      "source": [
        "## Transfer Learning in PyTorch\n",
        "\n",
        "Transfer learning is a machine learning technique where a model, developed for a particular task, is reused as a starting point for a model on a second task. It's a popular approach in deep learning because it can train deep neural networks with comparatively little data. This is very useful, as most real-world datasets are typically much smaller than the massive datasets (like ImageNet) used to train popular models.\n",
        "\n",
        "The core idea is to leverage the features learned from one task and apply them to another. In the context of neural networks, this means using the architecture and weights of a pre-trained model and adapting them to a new task.\n",
        "\n",
        "There are two main approaches in transfer learning:\n",
        "\n",
        "1. **Feature Extraction**: Here, we freeze all the layers of the pre-trained model except the final fully connected layer. This last layer is replaced with a new one that matches the number of classes in the new dataset and is trained from scratch.\n",
        "2. **Fine-tuning**: In this approach, we unfreeze some or all of the layers of the pre-trained model and train them on the new data. This can help in adapting the pre-trained features more closely to the new task.\n",
        "Let's see how to perform transfer learning using PyTorch.\n",
        "\n",
        "For more information about approaches to transfer learning and its significance: https://builtin.com/data-science/transfer-learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVWWw1F97b81"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# Load and preprocess an even smaller subset of CIFAR-10\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "full_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "train_size = int(0.02 * len(full_dataset))  # Using only 2% of the dataset\n",
        "_, train_subset = random_split(full_dataset, [len(full_dataset) - train_size, train_size])\n",
        "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Load a pre-trained model (using AlexNet for faster computation)\n",
        "model = models.alexnet(pretrained=True)\n",
        "\n",
        "# Freeze all layers\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Modify the final layer\n",
        "model.classifier[6] = nn.Linear(model.classifier[6].in_features, 10)\n",
        "\n",
        "# Define a loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.classifier[6].parameters(), lr=0.001)\n",
        "\n",
        "# Shortened training loop\n",
        "for epoch in range(2):  # Reduced to 2 epochs\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1}/2, Loss: {avg_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FC4ZnXYK_2YV"
      },
      "outputs": [],
      "source": [
        "# Split the CIFAR-10 dataset into training, validation, and test subsets\n",
        "val_size = int(0.02 * len(full_dataset))  # Using 2% for validation\n",
        "test_size = len(full_dataset) - train_size - val_size\n",
        "train_subset, val_subset, test_subset = random_split(full_dataset, [train_size, val_size, test_size])\n",
        "\n",
        "val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Evaluate the model's performance on the validation set\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy of the model on the validation images: {accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0XETckaIK8n"
      },
      "source": [
        "Keep in mind:\n",
        "\n",
        "- A randomly initialized model (without any training) would have an accuracy of about 10% since there are 10 classes.\n",
        "- A modest transfer learning approach like this, with only 2% of the data and 2 epochs, might achieve accuracies in the range of 40-60%, depending on various factors like the specific samples in the 2%.\n",
        "- More sophisticated models trained on the entire CIFAR-10 dataset can achieve accuracies above 90%."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advanced Applications with Real-world Data"
      ],
      "metadata": {
        "id": "W2wLCEZECBiA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4G8AAaTu1Ba"
      },
      "source": [
        "### Text Classification with LSTMs\n",
        "\n",
        "Text classification is a staple task in Natural Language Processing (NLP). The goal is to take a text input and assign it to one of the predefined classes. Examples of text classification include spam detection, sentiment analysis, and topic assignment.\n",
        "\n",
        "Long Short-Term Memory (LSTM) networks, a type of Recurrent Neural Network (RNN), are particularly well-suited for sequence-based tasks, including text classification. This is due to their capability to remember long-term dependencies in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtwYbpiWHu--"
      },
      "outputs": [],
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.datasets import IMDB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchtext.vocab import build_vocab_from_iterator, GloVe\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# Define the tokenizer\n",
        "tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "\n",
        "# Load the raw IMDB dataset\n",
        "raw_train_data, raw_test_data = IMDB()\n",
        "\n",
        "# Tokenize and preprocess the data\n",
        "def tokenize_and_preprocess(dataset):\n",
        "    tokenized_data = []\n",
        "    for label, text in dataset:\n",
        "        tokens = tokenizer(text)\n",
        "        # Convert to lowercase\n",
        "        tokens = [token.lower() for token in tokens]\n",
        "        tokenized_data.append((tokens, label))\n",
        "    return tokenized_data\n",
        "\n",
        "train_data = tokenize_and_preprocess(raw_train_data)\n",
        "test_data = tokenize_and_preprocess(raw_test_data)\n",
        "\n",
        "train_data, valid_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a function to return the tokenized data iterator\n",
        "def yield_tokens(data_iter):\n",
        "    for text, _ in data_iter:\n",
        "        yield from text\n",
        "\n",
        "# Build vocabulary with vectors directly\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_data), specials=['<unk>', '<pad>'])\n",
        "\n",
        "# Define the custom collate function\n",
        "def collate_batch(batch):\n",
        "    label_list, text_list, lengths_list = [], [], []\n",
        "    for (_text, _label) in batch:\n",
        "        label_list.append(label_pipeline(_label))\n",
        "        processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "        text_list.append(processed_text)\n",
        "        lengths_list.append(processed_text.size(0))\n",
        "    return torch.tensor(label_list, dtype=torch.float64), pad_sequence(text_list, padding_value=2.0), torch.tensor(lengths_list, dtype=torch.int64)\n",
        "\n",
        "# Define the text and label pipelines\n",
        "def text_pipeline(text):\n",
        "    return [vocab[token] for token in text]\n",
        "\n",
        "def label_pipeline(label):\n",
        "    return 1 if label == 'pos' else 0\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True, collate_fn=collate_batch)\n",
        "valid_loader = DataLoader(valid_data, batch_size=64, shuffle=False, collate_fn=collate_batch)\n",
        "test_loader = DataLoader(test_data, batch_size=64, shuffle=False, collate_fn=collate_batch)\n",
        "\n",
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, pad_idx):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_dim)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, text, text_lengths):\n",
        "        embedded = self.embedding(text)\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
        "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
        "        return self.fc(hidden.squeeze(0))\n",
        "\n",
        "# Note: Training the model would be the next step, but for conciseness, we're showcasing the setup here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KRavSPwTxlM"
      },
      "source": [
        "### Other Examples of Advanced Applications\n",
        "\n",
        "**Sentiment Analysis**\n",
        "\n",
        "Sentiment Analysis is an NLP sub-field aiming to deduce sentiment or emotion from text. Commonly applied to customer feedback, its primary goal is to categorize sentiment into classes like positive, negative, or neutral. For hands-on practice, the IMDB movie review dataset is a popular choice.\n",
        "\n",
        "**Image Segmentation**\n",
        "\n",
        "In Image Segmentation, images are divided into multiple segments or \"super-pixels\", converting them into more analyzable representations. Unlike image classification, which tags an entire image with one label, segmentation classifies each pixel. It can be:\n",
        "\n",
        "- **Semantic Segmentation**: Classifying each pixel based on the class of its enclosing object or region.\n",
        "- **Instance Segmentation**: Identifying each object instance per pixel.\n",
        "\n",
        "**Object Detection**\n",
        "\n",
        "Object Detection, a computer vision task, locates and classifies objects in images. It provides bounding boxes for detected objects, coupled with its class label. Several architectures cater to object detection, such as Faster R-CNN, YOLO, and SSD."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lTp0cvLVi-Z"
      },
      "source": [
        "### Training a Pre-trained Object Detector using Faster R-CNN\n",
        "\n",
        "Now that we've decided on object detection as our project focus, we'll be leveraging a pre-trained model for our task. Utilizing a pre-trained model, especially on tasks as complex as object detection, saves a significant amount of time and computational resources. Instead of training a model from scratch, we can use a model trained on a large dataset and fine-tune or directly deploy it for our specific use case.\n",
        "\n",
        "**Faster R-CNN** is one of the state-of-the-art architectures for object detection. It effectively combines the strengths of both Region-based Convolutional Networks (R-CNN) and Fast R-CNN, offering speed and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from torchvision.transforms import functional as F\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "# Load a pre-trained Faster R-CNN model\n",
        "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# Load an image\n",
        "def load_image_from_url(url):\n",
        "    \"\"\"\n",
        "    Loads an image from a given URL.\n",
        "    \"\"\"\n",
        "    response = requests.get(url)\n",
        "    return Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "\n",
        "# Input an image url - An example of a bicycle is given\n",
        "image_url = 'https://image-and-file-storage.storage.googleapis.com/images/library/large/trek-wahoo-26-345352-3363194-1.png'  # Bicycle Example\n",
        "image = load_image_from_url(image_url)\n",
        "\n",
        "\n",
        "# Apply transformations and pass image through the model\n",
        "transform = torchvision.transforms.ToTensor()\n",
        "image_tensor = transform(image).unsqueeze(0)\n",
        "predictions = model(image_tensor)\n",
        "\n",
        "# Hardcoded classes\n",
        "COCO_CLASSES = [\n",
        "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
        "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
        "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
        "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
        "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
        "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
        "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table', 'N/A',\n",
        "    'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
        "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
        "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
        "]\n",
        "\n",
        "def visualize_detection(img, prediction):\n",
        "    image_copy = img.copy()\n",
        "    draw = ImageDraw.Draw(image_copy)\n",
        "    boxes = prediction[0]['boxes'].detach().numpy()\n",
        "    scores = prediction[0]['scores'].detach().numpy()\n",
        "    labels = prediction[0]['labels'].detach().numpy()\n",
        "\n",
        "    # Define the threshold for scores. Only boxes with scores above this threshold will be drawn.\n",
        "    threshold = 0.5\n",
        "\n",
        "    # Use default font with specified size\n",
        "    font = ImageFont.load_default()\n",
        "\n",
        "    for box, score, label in zip(boxes, scores, labels):\n",
        "        if score > threshold:\n",
        "            draw.rectangle(list(box), outline='red', width=2)\n",
        "            draw.text((box[0], box[1]), f\"{COCO_CLASSES[label]}: {score:.2f}\", fill='red', font=font)\n",
        "    return image_copy\n",
        "\n",
        "# Get the visualized image\n",
        "result_image = visualize_detection(image, predictions)\n",
        "print(result_image)\n",
        "result_image.show()\n",
        "# Display the visualized image using matplotlib\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(result_image)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Nz2yZfv7PCZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving and Loading Trained Models:\n",
        "\n",
        "Once a model is trained, you'd want to save its architecture and trained parameters (weights) so that you can reuse it later without having to retrain it. This is especially true for models that take a long time to train.\n",
        "\n",
        "PyTorch Documentation for Saving and Loading Trained Models: https://pytorch.org/tutorials/beginner/saving_loading_models.html"
      ],
      "metadata": {
        "id": "d5eqAdMNns1X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the weights of a simple neural network:"
      ],
      "metadata": {
        "id": "XFK2YK_Sudbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model.py\n",
        "\n",
        "import torch\n",
        "\n",
        "# Define a simple neural network model\n",
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleModel, self).__init__()\n",
        "        self.fc = nn.Linear(10, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "model = SimpleModel()\n",
        "\n",
        "# Generating random data to simulate training\n",
        "inputs = torch.randn(100, 10)\n",
        "targets = torch.randn(100, 1)\n",
        "\n",
        "# Training the model for a few iterations\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "for _ in range(10):  # Train for 10 epochs\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# Saving the model weights to 'model_weights.pth'\n",
        "torch.save(model.state_dict(), 'model_weights.pth')  # Saving in the persistent storage directory\n"
      ],
      "metadata": {
        "id": "az5F7KBEuSNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('model.py', 'r') as f:\n",
        "    code = f.read()\n",
        "    exec(code)"
      ],
      "metadata": {
        "id": "XFJQUwH0YMov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZhhjmitQCi1"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load('model_weights.pth'))\n",
        "model.eval()  # Ensure the model is in evaluation mode"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model.eval() call is crucial when your model has layers like dropout or batch normalization that behave differently during training and evaluation."
      ],
      "metadata": {
        "id": "mDFq0Ef4oA82"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch to ONNX for Cross-platform Deployment (An Open Standard for Machine Learning Interoperability):\n",
        "\n",
        "ONNX (Open Neural Network Exchange) is an open format built to represent machine learning models. It allows developers to move models between state-of-the-art tools and choose the combination that is best for them. For more information on converting models into ONNX: https://deci.ai/blog/how-to-convert-a-pytorch-model-to-onnx/. Let's export a PyTorch model to ONNX:"
      ],
      "metadata": {
        "id": "lqXhTazloH6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.onnx\n",
        "\n",
        "# Create a dummy input that matches the model's input format\n",
        "dummy_input = torch.randn(1, 10)  # A random tensor of shape [1, 10]\n",
        "\n",
        "# Export the model to ONNX format\n",
        "torch.onnx.export(model, dummy_input, \"model.onnx\")\n"
      ],
      "metadata": {
        "id": "ONQ1jzMCn9VM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction to TorchServe for Deployment:\n",
        "\n",
        "TorchServe is a flexible tool for serving PyTorch models in production environments. It handles tasks like model versioning, logging, metrics, and more. Let's start using it! (Note: TorchServe usage is more involved and often requires setup tailored to the specific deployment environment, showing it here for the give a basic sense of how it works). For a far more detailed example of deploying a transfer learning CNN model with ResNet as the backbone: https://towardsdatascience.com/serving-pytorch-models-with-torchserve-6b8e8cbdb632"
      ],
      "metadata": {
        "id": "FfEzvNp5otDD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Install TorchServe:"
      ],
      "metadata": {
        "id": "lu1E6l-Xo5M-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchserve torch-model-archiver"
      ],
      "metadata": {
        "id": "5tfEoeHXojqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Package the Model:"
      ],
      "metadata": {
        "id": "VRmoSAj2pECB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!torch-model-archiver --model-name my_model --version 1.0 --model-file model.py --serialized-file model_weights.pth --handler image_classifier"
      ],
      "metadata": {
        "id": "KSztpwdmpDeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Start the TorchServe:"
      ],
      "metadata": {
        "id": "rU7xkPKspTd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir model_store\n",
        "!mv my_model.mar model_store/\n",
        "\n",
        "!torchserve --start --ncs --model-store model_store --models my_model=my_model.mar"
      ],
      "metadata": {
        "id": "ogpJx-9ppQIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Project - Lyric Completion\n",
        "## Data Collection\n",
        "\n",
        "For our project, we'll use a dataset of Beatles' lyrics! While there are many lyric datasets available, for simplicity, we will use a very small toy dataset (roughly 15,400 tokens) to demonstrate the process. This dataset contains cleaned lyrics from the Beatles' catalog of music. While it's rudimentary, it serves to demonstrate the process. In practice, you'd concatenate lyrics/text from multiple files, tokenize it, and prepare it for the model."
      ],
      "metadata": {
        "id": "gA15bKSx0Un_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gathering our dataset\n",
        "First, let's gather our data! For this project, we're using the `curl` tool to fetch our dataset directly from the crash course's repository."
      ],
      "metadata": {
        "id": "qsjxpbuz1HWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -o lyrics_dataset.csv https://raw.githubusercontent.com/nbetts2020/PyTorch-Crash-Course/main/data/lyrics_dataset.csv"
      ],
      "metadata": {
        "id": "MxNkhdgKaIkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Previewing the dataset"
      ],
      "metadata": {
        "id": "2mFC04DZsmsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Load the CSV file into a pandas DataFrame\n",
        "df_lyrics_csv = pd.read_csv(\"lyrics_dataset.csv\")\n",
        "# Convert all lyrics to lowercase\n",
        "df_lyrics_csv['lyrics'] = df_lyrics_csv['lyrics'].str.lower()\n",
        "\n",
        "# Remove leading and trailing whitespaces\n",
        "df_lyrics_csv['lyrics'] = df_lyrics_csv['lyrics'].str.strip()\n",
        "df_lyrics_csv['lyrics'].head()"
      ],
      "metadata": {
        "id": "G1wMvGYbNIpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Setup\n",
        "Next, we will load a pre-trained model. The GPT-2 model from HuggingFace's `transformers` library is a popular choice for text generation tasks. HuggingFace's description (We will be using the 355 million parameter GPT2-medium model. This is a small text generation model. For reference, GPT3 has 175 billion parameters): https://huggingface.co/gpt2-medium#:~:text=Model%20Description%3A%20GPT%2D2%20Medium,language%20modeling%20(CLM)%20objective."
      ],
      "metadata": {
        "id": "xNXd2p1oq9C0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "wiBc7Xfsrm2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Config, AdamW, get_linear_schedule_with_warmup\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "\n",
        "# Setting up the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load pre-trained GPT-2 tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2-medium')\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Model configuration\n",
        "configuration = GPT2Config.from_pretrained('gpt2-medium', output_hidden_states=False)\n",
        "\n",
        "# Load pre-trained GPT-2 model\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2-medium', config=configuration)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "model.to(device)\n",
        "\n",
        "# Define some hyperparameters\n",
        "EPOCHS = 10\n",
        "LEARNING_RATE = 3e-4\n",
        "WARMUP_STEPS = 1e2\n",
        "MAX_LEN = 400\n",
        "TRAIN_BATCH_SIZE = 2\n",
        "VAL_BATCH_SIZE = 1\n",
        "\n",
        "# Dataset class for lyrics\n",
        "class LyricsDataset(Dataset):\n",
        "\n",
        "    def __init__(self, df, tokenizer, gpt2_type=\"gpt2\", max_length=MAX_LEN):\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.input_ids = []\n",
        "        self.attn_masks = []\n",
        "\n",
        "        for index, row in df.iterrows():\n",
        "            encodings_dict = tokenizer(row['lyrics'], truncation=True,\n",
        "                                       max_length=max_length, padding=\"max_length\")\n",
        "\n",
        "            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
        "            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.attn_masks[idx]\n",
        "\n",
        "# Create DataLoader for lyrics\n",
        "train_dataset = LyricsDataset(df_lyrics_csv, tokenizer)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# Optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP_STEPS, num_training_steps=-1)"
      ],
      "metadata": {
        "id": "yALyHGT203Jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we've set up the model, tokenizer, and dataloader, the next step involves training our model on the lyric dataset."
      ],
      "metadata": {
        "id": "lsTkxxne1ZYj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning the GPT-2 Model\n",
        "Now that we have everything set up, we will proceed to fine-tune the GPT-2 model on our lyric dataset. Fine-tuning allows the pre-trained model to adapt to the specific style and structure of the lyrics, enabling it to generate more coherent and contextually relevant lyric completions later on."
      ],
      "metadata": {
        "id": "IYobTcvt9E2t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Splitting\n",
        "To ensure our model doesn't overfit to our training data, it's essential to evaluate its performance on unseen data, called validation data. We'll start by splitting our data into training and validation sets."
      ],
      "metadata": {
        "id": "mfgcNItPMQon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Splitting the dataset into training and validation sets (80-20 split for this example)\n",
        "train_df, val_df = train_test_split(df_lyrics_csv, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "snVqSEq8MP7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DataLoader Setup\n",
        "Now that we have our data split, let's prepare DataLoaders for both training and validation datasets."
      ],
      "metadata": {
        "id": "IzLX6v7tMXO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = LyricsDataset(train_df, tokenizer)\n",
        "val_dataset = LyricsDataset(val_df, tokenizer)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=VAL_BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "qgzXjZX8MVZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Fine-tuning\n",
        "For the fine-tuning process, we'll:\n",
        "\n",
        "1. Feed our training data into the model.\n",
        "2. Compute the training loss.\n",
        "3. Backpropagate the error to adjust the model weights."
      ],
      "metadata": {
        "id": "BvZjWVGbMpgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function\n",
        "def train_epoch(model, data_loader, optimizer, device, scheduler, n_examples):\n",
        "    model = model.train()\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    for batch in data_loader:\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_labels = batch[0].to(device)\n",
        "        b_masks = batch[1].to(device)\n",
        "\n",
        "        outputs = model(b_input_ids, attention_mask=b_masks, labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(data_loader)\n",
        "\n",
        "    return avg_train_loss"
      ],
      "metadata": {
        "id": "ipHFUR7KMbm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Evaluation\n",
        "After each epoch of training, we'll evaluate the model on our validation data. This will help us understand how well the model is generalizing."
      ],
      "metadata": {
        "id": "BRgG0JzGMyHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation function\n",
        "def eval_epoch(model, data_loader, device):\n",
        "    model = model.eval()\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            b_input_ids = batch[0].to(device)\n",
        "            b_labels = batch[0].to(device)\n",
        "            b_masks = batch[1].to(device)\n",
        "\n",
        "            outputs = model(b_input_ids, attention_mask=b_masks, labels=b_labels)\n",
        "            loss = outputs[0]\n",
        "            total_loss += loss.item()\n",
        "    return total_loss / len(data_loader)"
      ],
      "metadata": {
        "id": "eIzozD7TMxqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine-tuning and Evaluation Loop\n",
        "Now that our functions are set up, we'll proceed with the fine-tuning and evaluation loop."
      ],
      "metadata": {
        "id": "KjaZkktxM5_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tuning and evaluating the model\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
        "    print(\"-\" * 10)\n",
        "\n",
        "    train_loss = train_epoch(model, train_dataloader, optimizer, device, scheduler, len(train_dataset))\n",
        "    print(f\"Train loss: {train_loss:.4f}\")\n",
        "\n",
        "    val_loss = eval_epoch(model, val_dataloader, device)\n",
        "    print(f\"Validation loss: {val_loss:.4f}\\n\")"
      ],
      "metadata": {
        "id": "Zr0v7n3sM217"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating Lyrics using the Fine-tuned Model\n",
        "After training and evaluating our model, we can now use it to generate lyric completions. By feeding a prompt to the model, it can predict the subsequent tokens and provide suggestions for lyric continuation."
      ],
      "metadata": {
        "id": "z76VIxP19f2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_lyrics(prompt, max_length=50):\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "    attention_mask = torch.ones(input_ids.shape, device=device)\n",
        "    output = model.generate(input_ids, attention_mask=attention_mask, max_length=max_length, temperature=0, num_return_sequences=5, num_beams=5)\n",
        "    return [tokenizer.decode(gen_code, skip_special_tokens=True, clean_up_tokenization_spaces=True) for gen_code in output]\n",
        "\n",
        "prompt = \"When I looked out my window I saw\"\n",
        "generated_codes = generate_lyrics(prompt)\n",
        "for i, code in enumerate(generated_codes):\n",
        "    print(f\"Suggestion {i + 1}:\\n{code}\\n{'-' * 50}\\n\")"
      ],
      "metadata": {
        "id": "qG9VIYxgtCdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Repetitive Isn't It?\n",
        "Such repetition can stem from various factors like the model overfitting to certain patterns in the training data, or from nuances in the generation algorithm itself. While the model is technically doing what it's trained to dopredicting the next most likely wordit can sometimes get \"stuck\" in a loop, leading to such repetitive sequences.\n",
        "\n",
        "To address this, we need a smarter approach. One that's more aware of the context and can dynamically adapt to ensure diversity in the generated content.\n",
        "\n",
        "In the next cell, we'll introduce an improved version of our text generation function. This new function will incorporate mechanisms to detect and counteract repetitive sequences, ensuring more varied and contextually relevant outputs. Let's dive in:"
      ],
      "metadata": {
        "id": "zO6lSSLd7t26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_lyrics_with_penalty(prompt, max_length=50, repetition_penalty=0.1):\n",
        "    model.eval()  # Ensure model is in evaluation mode\n",
        "\n",
        "    # Encode the prompt and get the initial input tensor\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Empty list to store the generated sequences\n",
        "    generated_sequences = []\n",
        "\n",
        "    for _ in range(5):  # Generate 5 sequences\n",
        "        sequence_input_ids = input_ids.clone()\n",
        "\n",
        "        # Generate tokens one-by-one\n",
        "        for _ in range(max_length):\n",
        "            with torch.no_grad():\n",
        "                outputs = model(sequence_input_ids)\n",
        "\n",
        "            # Get logits from model outputs\n",
        "            logits = outputs.logits[:, -1, :]\n",
        "\n",
        "            # Apply repetition penalty to logits of already generated tokens\n",
        "            for token_id in sequence_input_ids[0]:\n",
        "                logits[0, token_id] -= repetition_penalty\n",
        "\n",
        "            # Sample a token from the adjusted logits\n",
        "            next_token_id = torch.multinomial(torch.nn.functional.softmax(logits, dim=-1), num_samples=1).squeeze(0)\n",
        "\n",
        "            # Append the sampled token to the sequence\n",
        "            sequence_input_ids = torch.cat((sequence_input_ids, next_token_id.unsqueeze(1)), dim=1)\n",
        "\n",
        "            # Decode the generated sequence and add to the list\n",
        "            generated_sequence = tokenizer.decode(sequence_input_ids[0], skip_special_tokens=True)\n",
        "            generated_sequences.append(generated_sequence)\n",
        "\n",
        "    return generated_sequences\n",
        "\n",
        "prompt = \"When I looked out my window I saw\"\n",
        "max_length = 50\n",
        "generated_codes = generate_lyrics_with_penalty(prompt, max_length)\n",
        "for i, code in enumerate(generated_codes):\n",
        "    if (i+1) % max_length == 0:\n",
        "        print(f\"Suggestion {(i + 1)//max_length}:\\n{code}\\n{'-' * 50}\\n\")"
      ],
      "metadata": {
        "id": "L66-gzFZ9NNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# And in the end...\n",
        "\n",
        "That's a wrap! In this PyTorch Crash Course we learned:\n",
        " - The basics of PyTorch (Tensors, Reshaping tensors, Broadcasting)\n",
        " - Building a Basic Neural Network (What are Layers?, Activation functions, Feed forward networks)\n",
        " - Building an Advanced Neural Network (CNNs, RNNs, Evaluating Models)\n",
        " - Regularization and Optimization Techniques (Dropout, Batch Normalization, Learning Rate)\n",
        " - Transfer Learning\n",
        " - Text Classification with LSTMs\n",
        " - Inference with an R-CNN Object Detection Model\n",
        " - The Basics of Saving and Loading Trained Models (ONNX, TorchServe)\n",
        " - Fine-Tuning Transformer Based Architectures (Tokenizing a Dataset, GPT2-Medium, Text Completion, Repetitive Token Deterrence)\n",
        "\n",
        "\n",
        "And a whole lot more!\n",
        "\n",
        "Thank you to everyone who checked out this course! This notebook is provided under the MIT License, permitting you to use, adapt, and share it though still retaining the original attribution.\n",
        "\n",
        "Email: nbettencourt2020@gmail.com\n",
        "\n",
        "GitHub: https://github.com/nbetts2020\n",
        "\n",
        "LinkedIn: https://www.linkedin.com/in/nicholas-bettencourt/"
      ],
      "metadata": {
        "id": "9u4UddaD6jdP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RP-D0EE9MVpO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}